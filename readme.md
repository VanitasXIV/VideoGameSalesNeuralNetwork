# Proyecto de Clasificaci贸n: xito de Ventas de Videojuegos (MLPClassifier con Scikit-learn)

Este proyecto implementa una Red Neuronal Artificial (RNA) utilizando `MLPClassifier` de Scikit-learn para clasificar si un videojuego tendr谩 茅xito en ventas a nivel global (Ventas Globales $\ge 1.0$ mill贸n).

## 1. Definici贸n de la Columna Objetivo

### Pregunta: 驴Qu茅 es la columna objetivo (`Exito_Ventas`) y c贸mo se define?

La columna objetivo (`Exito_Ventas`) es una variable de **clasificaci贸n binaria (0 o 1)** que transforma el problema de regresi贸n de ventas en un problema de **clasificaci贸n** (茅xito/no 茅xito).

* **Valor 1 (xito):** Asignado si las `Global_Sales` (Ventas Globales) son mayores o iguales a $1.0$ mill贸n de unidades.
* **Valor 0 (No xito):** Asignado si las `Global_Sales` son menores a $1.0$ mill贸n de unidades.

---

## 2. Origen de Datos, Variables y An谩lisis Exploratorio

El c贸digo procesa el dataset `"video games sales.csv"` obtenido de Kaggle.

### Origen y Contexto de los Datos

El dataset contiene informaci贸n hist贸rica sobre ventas de videojuegos, incluyendo:

* **Ventas Regionales:** M煤ltiples variables de ventas clasificadas por ubicaci贸n: `NA_Sales` (Norteam茅rica), `EU_Sales` (Europa), `JP_Sales` (Jap贸n), y `Other_Sales`.
* **Caracter铆sticas del Juego:** Variables como `Platform`, `Genre`, `Publisher`, `Rank` y `Year`.

### Pasos del An谩lisis Exploratorio (AE) y Transformaciones

| Paso | Descripci贸n de la Tarea | Observaci贸n Clave |
| :--- | :--- | :--- |
| **Creaci贸n Objetivo** | Se crea la variable binaria `Exito_Ventas`. | Permite abordar el problema con un modelo de clasificaci贸n. |
| **Detecci贸n de Outliers (IQR)** | Se eval煤a la presencia de valores extremos en las columnas de ventas. | Se detecta la **presencia de numerosos outliers** en las m茅tricas de ventas para detectar valores at铆picos |
| **Correlaci贸n** | Se analiza la correlaci贸n de variables num茅ricas con `Exito_Ventas`. | Se espera una alta correlaci贸n entre las ventas regionales y el 茅xito global. |
| **Normalizaci贸n** | Se aplica `MinMaxScaler` a las columnas de ventas. | Las caracter铆sticas se escalan al rango $[0, 1]$, mejorando la estabilidad y velocidad de convergencia de la Red Neuronal. |
| **Codificaci贸n** | Se aplica `pd.get_dummies` a `Platform`, `Genre`, y `Publisher`. | Las variables categ贸ricas se convierten a un formato num茅rico (*one-hot encoding*) utilizable por el `MLPClassifier`. |

---

## 3. Modelado, Validaciones y Optimizaciones

Se utiliza un clasificador de Red Neuronal Artificial para el problema de clasificaci贸n binaria.

Una **Red Neuronal Artificial (RNA) tipo Feedforward** es la arquitectura de red neuronal **m谩s b谩sica y fundamental**. Se caracteriza porque el flujo de informaci贸n es **unidireccional** y **sin ciclos**.

### Caracter铆sticas Clave

1.  **Flujo Unidireccional:** La informaci贸n solo viaja hacia adelante (de "izquierda" a "derecha") :
    * Comienza en la **capa de entrada**.
    * Pasa por una o m谩s **capas ocultas**.
    * Termina en la **capa de salida**.
2.  **Sin Bucles:** No hay conexiones que permitan que la salida de una neurona retroceda a una capa anterior o a la misma capa, lo que la diferencia de las redes recurrentes (RNN).
3.  **Aplicaci贸n:** Es ideal para tareas de **clasificaci贸n** (como la utilizada en el proyecto) y **regresi贸n**, donde se mapea una entrada a una salida sin depender de la secuencia o el tiempo.

El modelo **`MLPClassifier`** (Multi-layer Perceptron Classifier) utilizado en este proyecto es un ejemplo can贸nico de una RNA Feedforward.

### Modelo Elegido: `MLPClassifier`

El modelo utilizado es el **Multi-layer Perceptron Classifier** (`MLPClassifier`), que es una RNA tipo *Feedforward*.

* **Arquitectura:** Dos capas ocultas con tama帽o `(64, 32)`, proporcionando una capacidad significativa para modelar relaciones **no lineales**.
* **Funci贸n de Activaci贸n:** Se utiliza **ReLU** (`activation='relu'`).

### Validaciones, Optimizaciones y Regularizaciones

| T茅cnica | Implementaci贸n en el C贸digo | Prop贸sito |
| :--- | :--- | :--- |
| **Validaci贸n** | **Divisi贸n de datos 80/20** (`train_test_split`). | Crea un conjunto de validaci贸n (`X_val, y_val`) independiente para evaluar el modelo y aplicar *Early Stopping*. |
| **Optimizaci贸n/Regularizaci贸n** | **`Early Stopping`** (Implementaci贸n manual con `patience = 20`). | Previene el **sobreajuste (overfitting)** deteniendo el entrenamiento si la precisi贸n en el conjunto de validaci贸n no mejora durante un n煤mero (`patience`) de 茅pocas. |
| **Optimizaci贸n** | **`warm_start=True`** y `max_iter=1` en el bucle. | Permite el **entrenamiento incremental** 茅poca por 茅poca, reutilizando los pesos de la 茅poca anterior en lugar de re-inicializar el modelo en cada llamada a `clf.fit()`. |
| **Regularizaci贸n** | **Ajuste de Hiperpar谩metros** (`learning_rate_init=0.05`). | Controla el tama帽o de los pasos durante el descenso de gradiente, afectando la estabilidad y la velocidad de convergencia. |

##  Explicaci贸n de T茅rminos Clave (MLPClassifier)

A continuaci贸n, hay conceptos clave de optimizaci贸n y validaci贸n implementados en el c贸digo, importantes para el entrenamiento de la Red Neuronal (`MLPClassifier`).

---

### **1. Validaci贸n y Regularizaci贸n**

#### **Early Stopping** (Parada Temprana)

El **Early Stopping** es una t茅cnica de **regularizaci贸n** y **optimizaci贸n** que tiene como objetivo principal evitar el **sobreajuste (overfitting)**.

* **Mecanismo:** El entrenamiento se detiene antes de alcanzar el m谩ximo n煤mero de 茅pocas (`max_epochs`).
* **Criterio:** La detenci贸n ocurre cuando el rendimiento del modelo (generalmente la precisi贸n o la p茅rdida) en el conjunto de **validaci贸n** deja de mejorar durante un n煤mero predefinido de iteraciones, conocido como **paciencia** (`patience`).
* **Beneficio:** Evita que el modelo aprenda demasiado los ruidos del conjunto de entrenamiento, preservando su capacidad de **generalizaci贸n** sobre datos no vistos. 

#### **Overfitting** (Sobreajuste)

El **sobreajuste** es un fen贸meno que ocurre cuando un modelo de Machine Learning aprende los datos de entrenamiento **demasiado bien**, incluyendo el ruido o los detalles irrelevantes de esos datos.

* **Resultado:** El modelo muestra un rendimiento **excelente** en el conjunto de **entrenamiento**, pero un rendimiento **pobre** y resultados poco confiables en el conjunto de **validaci贸n** o de prueba.

---

### **2. Optimizaci贸n y Control del Entrenamiento**

#### **Warm Start**

El par谩metro `warm_start=True` en `MLPClassifier` se utiliza para permitir el **entrenamiento incremental** del modelo.

* **Mecanismo:** Cuando se llama al m茅todo `fit()` varias veces, el modelo **reutiliza los pesos y sesgos** aprendidos en la llamada anterior en lugar de re-inicializarlos aleatoriamente.
* **Uso en el C贸digo:** Combinado con `max_iter=1`, esto simula un entrenamiento paso a paso, 茅poca por 茅poca, lo cual es necesario para la implementaci贸n manual del **Early Stopping**.

#### **Learning Rate Init** (Tasa de Aprendizaje Inicial)

El `learning_rate_init` es un **hiperpar谩metro** que define el tama帽o del paso que el algoritmo de optimizaci贸n (como Adam o SGD) da para ajustar los pesos del modelo durante el descenso del gradiente.

* **Descenso del Gradiente:** Es el proceso por el cual el modelo minimiza su funci贸n de p茅rdida.
* **Impacto:**
    * **Tasa Alta:** El modelo converge m谩s r谩pido, pero puede **saltarse el m铆nimo** o volverse inestable.
    * **Tasa Baja:** El modelo es m谩s estable, pero tarda mucho m谩s en converger o puede quedarse atascado en un m铆nimo local.
* **Ajuste:** El valor `0.05` es una **tasa de aprendizaje** espec铆fica seleccionada para encontrar un buen equilibrio entre estabilidad y velocidad de convergencia.